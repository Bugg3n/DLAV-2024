{"cells":[{"cell_type":"markdown","metadata":{"id":"AyPbJlzoyA5N"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","# Linear Classification\n","\n"," Implement Linear Classification using pytorch. This consists of having fully connected layers connected one after the other and ReLu activation functions between them.\n"," \n"," Build a neural network with a minimun of 2 layers in order to do classification."]},{"cell_type":"markdown","metadata":{"id":"Stm2Nhxlso2r"},"source":["Permit the notebook to access your drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESXccfIu1H7u"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"whJSL42iyA5S"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x2db22d89e70>"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import numpy as np\n","import torch.utils.data as utils\n","import time\n","import pdb\n","from torch.utils.data.sampler import SubsetRandomSampler\n","%matplotlib inline\n","\n","torch.manual_seed(1)    # reproducible"]},{"cell_type":"markdown","metadata":{"id":"zeTqh7pgs0JA"},"source":["Get the dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zahsf3gOyA5U"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data\\cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:08<00:00, 19750832.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ../data\\cifar-10-python.tar.gz to ../data\n","Files already downloaded and verified\n"]}],"source":["def get_train_valid_loader(data_dir='../data',\n","                           batch_size=64,\n","                           augment=False,\n","                           random_seed = 1,\n","                           valid_size=0.02,\n","                           shuffle=True,\n","                           show_sample=False,\n","                           num_workers=4,\n","                           pin_memory=False):\n","    \"\"\"\n","    Utility function for loading and returning train and valid\n","    multi-process iterators over the CIFAR-10 dataset. A sample\n","    9x9 grid of the images can be optionally displayed.\n","    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n","    Params\n","    ------\n","    - data_dir: path directory to the dataset.\n","    - batch_size: how many samples per batch to load.\n","    - augment: whether to apply the data augmentation scheme\n","      mentioned in the paper. Only applied on the train split.\n","    - random_seed: fix seed for reproducibility.\n","    - valid_size: percentage split of the training set used for\n","      the validation set. Should be a float in the range [0, 1].\n","    - shuffle: whether to shuffle the train/validation indices.\n","    - show_sample: plot 9x9 sample grid of the dataset.\n","    - num_workers: number of subprocesses to use when loading the dataset.\n","    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n","      True if using GPU.\n","    Returns\n","    -------\n","    - train_loader: training set iterator.\n","    - valid_loader: validation set iterator.\n","    \"\"\"\n","    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n","    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n","\n","    normalize = transforms.Normalize(\n","        mean=[0.4914, 0.4822, 0.4465],\n","        std=[0.2023, 0.1994, 0.2010],\n","    )\n","\n","    # define transforms\n","    valid_transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            normalize,\n","    ])\n","    if augment:\n","        train_transform = transforms.Compose([\n","            transforms.RandomCrop(32, padding=4),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","    else:\n","        train_transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","\n","    # load the dataset\n","    train_dataset = datasets.CIFAR10(\n","        root=data_dir, train=True,\n","        download=True, transform=train_transform,\n","    )\n","\n","    valid_dataset = datasets.CIFAR10(\n","        root=data_dir, train=True,\n","        download=True, transform=valid_transform,\n","    )\n","\n","    num_train = len(train_dataset)\n","    indices = list(range(num_train))\n","    split = int(np.floor(valid_size * num_train))\n","\n","    if shuffle:\n","        np.random.seed(random_seed)\n","        np.random.shuffle(indices)\n","\n","    train_idx, valid_idx = indices[split:], indices[:split]\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=batch_size, sampler=train_sampler,\n","        num_workers=num_workers, pin_memory=pin_memory,\n","    )\n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_dataset, batch_size=batch_size, sampler=valid_sampler,\n","        num_workers=num_workers, pin_memory=pin_memory,\n","    )\n","\n","    # visualize some images\n","    if show_sample:\n","        sample_loader = torch.utils.data.DataLoader(\n","            train_dataset, batch_size=9, shuffle=shuffle,\n","            num_workers=num_workers, pin_memory=pin_memory,\n","        )\n","        data_iter = iter(sample_loader)\n","        images, labels = data_iter.next()\n","        X = images.numpy().transpose([0, 2, 3, 1])\n","        plot_images(X, labels)\n","\n","    return (train_loader, valid_loader)\n","\n","trainloader, valloader = get_train_valid_loader()"]},{"cell_type":"markdown","metadata":{"id":"dr58pZjGs3fF"},"source":["Define the network"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"OYHld_YfyA5Z"},"outputs":[],"source":["class Net(torch.nn.Module):\n","    def __init__(self, n_feature, n_hidden, n_output):\n","        super(Net, self).__init__()\n","        \n","        ################################################################################\n","        # TODO:                                                                        #\n","        # Define 2 or more different layers of the neural network                      #\n","        ################################################################################\n","        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n","        \n","        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        \n","        self.fc1 = torch.nn.Linear(64 * 4 * 4, 128)\n","        self.fc2 = torch.nn.Linear(128, n_output)\n","        \n","        # Dropout layer (to prevent overfitting)\n","        self.dropout = torch.nn.Dropout(0.5)\n","        ################################################################################\n","        #                              END OF YOUR CODE                                #\n","        ################################################################################\n","\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0),-1)\n","        ################################################################################\n","        # TODO:                                                                        #\n","        # Set up the forward pass that the input data will go through.                 #\n","        # A good activation function betweent the layers is a ReLu function.           #\n","        ################################################################################\n","        # Apply conv follow by relu then pool\n","        x = x.view(-1, 3, 32, 32)\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = x.view(-1, 64 * 4 * 4)\n","        x = self.dropout(x)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)  # No activation function, as this will be handled by the loss function for multi-class classification\n","        \n","        ################################################################################\n","        #                              END OF YOUR CODE                                #\n","        ################################################################################\n","        return x"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"E0ynI2OZyA5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Net(\n","  (hidden): Linear(in_features=3072, out_features=50, bias=True)\n","  (relu): ReLU()\n","  (output): Linear(in_features=50, out_features=10, bias=True)\n",")\n"]}],"source":["################################################################################\n","# TODO:                                                                        #\n","# Define the parameters of the network the way you want it to be.              #\n","# Choose an Optimizer that will be used to minimize the loss function.         #\n","################################################################################\n","net = Net(n_feature=3072, n_hidden=100, n_output=10)     # define the network\n","print(net)  # net architecture\n","\n","# Loss and Optimizer (Try different learning rates)\n","# Softmax is internally computed.\n","# Set parameters to be updated. \n","\n","learning_rate = 0.004\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  # Choose the optimizer you want and tune its hyperparameter\n","loss_func = torch.nn.CrossEntropyLoss()  # the target label is NOT an one-hotted\n","################################################################################\n","#                              END OF YOUR CODE                                #\n","################################################################################"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"FBUs_zOVyA5b"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\HugoWestergård\\AppData\\Local\\Temp\\ipykernel_23704\\353824247.py:35: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  _, predicted = torch.max(F.softmax(outputs).data, 1)\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the 1000 val images:                     32 %\n","Accuracy of the network on the 1000 val images:                     33 %\n","Accuracy of the network on the 1000 val images:                     33 %\n","Accuracy of the network on the 1000 val images:                     34 %\n","Accuracy of the network on the 1000 val images:                     36 %\n","Accuracy of the network on the 1000 val images:                     38 %\n","Accuracy of the network on the 1000 val images:                     38 %\n","Accuracy of the network on the 1000 val images:                     37 %\n","Accuracy of the network on the 1000 val images:                     38 %\n","Accuracy of the network on the 1000 val images:                     36 %\n","Accuracy of the network on the 1000 val images:                     39 %\n","Accuracy of the network on the 1000 val images:                     40 %\n","Accuracy of the network on the 1000 val images:                     40 %\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[17], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m          \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m          \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n","File \u001b[1;32mc:\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n","File \u001b[1;32mc:\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n","File \u001b[1;32mc:\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#traindataset = utils.TensorDataset(X_train, y_train)\n","#trainloader = utils.DataLoader(traindataset, batch_size=64, shuffle=True)\n","\n","epochs = 10\n","steps = 0\n","print_every = 20\n","for e in range(epochs):\n","    start = time.time()\n","    for images, labels in iter(trainloader):\n","        steps += 1\n","        ################################################################################\n","        # TODO:                                                                        #\n","        # Run the training process                                                     #\n","        #                                                                              #\n","        ################################################################################\n","        optimizer.zero_grad()\n","        outputs = net(images)\n","        loss = loss_func(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        ################################################################################\n","        #                              END OF YOUR CODE                                #\n","        ################################################################################\n","    \n","        if steps % print_every == 0:\n","                stop = time.time()\n","                # Test accuracy\n","                net.eval()\n","                correct = 0\n","                total = 0\n","                with torch.no_grad():\n","                    for data in valloader:\n","                          images, labels = data\n","                          outputs = net(images)\n","                          _, predicted = torch.max(F.softmax(outputs).data, 1)\n","                          total += labels.size(0)\n","                          correct += (predicted == labels).sum().item()\n","\n","                    print('Accuracy of the network on the %d val images: \\\n","                    %d %%' % (total,100 * correct / total))\n","\n","                start = time.time()"]},{"cell_type":"markdown","metadata":{"id":"7gx02lf4yA5c"},"source":["After training, the model should be saved to be tested on the test dataset or to be used in a real-life application. To save your model in pytorch:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cTzmX0nZyA5c"},"outputs":[],"source":["torch.save(net.state_dict(), 'drive/MyDrive/Colab Notebooks/linearClassifier_pytorch.ckpt')"]},{"cell_type":"markdown","metadata":{"id":"JdGRq6H7yA5d"},"source":["Remeber the above path. You need to load your trained model in another notebook:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0q1qkYsyA5e"},"outputs":[],"source":["checkpoint = torch.load(\"drive/MyDrive/Colab Notebooks/linearClassifier_pytorch.ckpt\")\n","net.load_state_dict(checkpoint)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Linear Classification pytorch.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"nteract":{"version":"0.12.3"}},"nbformat":4,"nbformat_minor":0}
